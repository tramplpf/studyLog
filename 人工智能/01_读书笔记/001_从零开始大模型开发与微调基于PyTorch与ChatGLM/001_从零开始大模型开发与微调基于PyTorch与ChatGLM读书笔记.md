# 《从零开始大模型开发与微调基于PyTorch与ChatGLM》

## 书籍信息

作者： 王晓华

ISIN：978-7-302-64707-2

 出版社： 清华大学出版社

版次： 2023年11月第1版





前言：

掌握PyTorch程序设计基本技能的程序设计人员成为当前各组织和单位热切寻求的热门人才。他们的主要工作就是利用获得的数据集设计不同额度人工神经模型，利用人工神经网络强大的学习能力提取和挖掘数据集中包含的潜在信息，编写相应的Pytorch程序对数据进行处理，对其价值进行进一步开发，魏商业机会的获取，管理模式的创建，决策的制定提供相应的支持。



Pytorch和深度学习需要相关研究人员对隐藏在其代码背后的理论进行学习，掌握一定的数据知识和理论基础的。

人工智能的代表---清华大学开发的ChatGLM是现阶段人工智能最高端的研究成果。在金融领域，ChatGLM可以帮助银行和证券公司进行风险控制和投资决策。 



本书目的： 以了解和掌握最强的人工智能模型ChatGLM，进行可靠的二次开发和微调为目标，使读者能够在开发者的层面掌握ChatGLM程序设计方法和技巧，为开发出更强大的人工智能大模型打下扎实的基础。 





## 第一章 新时代的曙光--人工智能与大模型



生成式人工智能（Generative Artificial Intelligence） 是一种基于机器学习技术的人工智能算法，其目的是通过学习大量数据和模式，生成新的，原创的内容。

生成式人工智能通常拆用深度学习模型，如<font color="red"> 循环神经网络（Recurrent Neural Network， RNN）</font>，<font color="red">变分自编码器（Variational Auto Encoder， VAE）</font> 等。来生成高质量的内容。

人工智能研究已成为<font color="red">计算机科学，数学，哲学，心理学等</font> 多个学科的交叉领域。 

人工智能正逐渐成为<font color="red">一种强大的工具</font> 和<font color="blue">智能化的基础设施</font> 。 

* 早期的人工智能主要集中在 <font color="red">专家系统</font>,<font color="red">规则引擎</font>,<font color="red">逻辑推理</font>等领域
* 随着深度学习和神经网络的兴起，人工智能进入了一个新的发展阶段。
  * 深度学习是一种基于神经网络的机器学习方法，能够自动地学习和提取数据中的特征，实现对复杂模式的识别和分类，适用于图像识别，语音识别，自然语言处理等领域。 



人工智能分类

* 人工智能 1.0 时代（2012-2017） 
  * 2012年，AlexNet模型问世开启了卷积神经网络（Convolutional Neural Network， CNN）在图像识别领域的应用。
  * 人工智能1.0 时代面临着模型碎片化，AI泛化能力不足等问题
* 人工智能2.0时代（2017年）
  * 2017年Google Brain团队提出了Transfromer架构，奠定了大模型领域的主流算法基础。
  * 预训练+微调的大模型有效解决了1.0时代泛化能力不足的问题。



传统的机器学习算法（如<font color="red">决策树，支持向量机</font>等）主要依赖于人工选择和提取特征，然后将这些特征输入模型中进行训练和分类。

而<font color="red">深度学习</font> 通过构建多层神经网络实现对特征的自动提取和学习，大大提高了模型的性能和准确率。

深度学习的核心是<font color="red">神经网络</font>，它可以被看作是由许多个简单的<font color="red">神经元</font>组成的网络。这些神经元可以接收输入并产生输出，通过学习不同的权重来实现不同的任务。<font>深度学习的深度</font>指的是神经网络的层数，即多层神经元的堆叠。在多层神经网络中，每一层的输出都是下一层的输入，每一层都负责提取<font color="red">不同层次的特征</font>，从而完成更加复杂的任务。

深度学习在人工智能领域的成功得益于其强大的<font color="red">表征学习能力</font>。  <font color="blue">表征学习能力是指从输入数据中学习到抽象的特征表示的过程。 </font> 深度学习模型可以自动地学习到数据的特征表示，并从中提取出具有区分性的特征，从而实现对数据的分类，识别等任务。 



工欲善其事，必先利其器。 

<font color="red">PyTorch</font>是一个Python开源机器学习库。它可以提供强大的GPU加速张量运算和动态计算图，方便用户进行快速实验和开发。 是由<font color="red">Facebook的人工智能研究小组于2016年发布</font>，当时它作为Torch的Python版，目的是解决Torch在Python中使用的不便之处。

Torch是另一个开源机器学习库。主要基于Lua编程语言。Torch最初是为了解决语音识别的问题而创建的，但随着时间的推移，Torch开始被广泛应用于其他机器学习领域，包括计算机视觉，自然语言处理，强化学习等。 

PyTorch2.0版本和1.x版本相比有了颠覆式的变化。PyTorch2.0中发布了大量足以改变PyTorch使用方式的新功能，它提供了相同的Eager Mode和用户体验，同时通过torch.compile增加了一个<font color="red">编译模式</font>，在训练和推理过程中可以对模型进行加速，从而提供更佳的性能和对Dynamic Shapes 及Distributed的支持。 



### 大模型

<font color="red">大模型是指具有非常多参数数量的人工神经网络模型</font>，在深度学习领域，大模型通常是指具有数亿到数万亿参数的模。这些模型通常需要在大规模数据集上进行训练，并且需要使用大量的计算资源进行优化和调整。 



人工智能正处于从"能用"到“好用”的应用落地阶段，但仍处于落地初期，主要面临场景需求碎片化，人力研发和应用计算成本高，以及长尾场景数据较少导致模型训练精度不够，模型算法从实验室场景到真实场景差距较大等行业问题。



在深度学习技术出现的近10年里，模型基本上都是针对特定的应用场景进行训练的，即小模型属于传统的定制化，作坊式的模型开发方式。传统人工智能模型需要完成从研发到应用全方位流程，包括需求定义，数据收集，模型算法设计，训练调优，应用部署和运营维护等阶段组成的整套流程。



<font color="red">大模型是从庞大，多类型的场景数据中学习，总结出不同场景，不同业务的通用能力，学习出一种特征和规律，成为具有泛化能力的模型库。</font>



<font color="red">大模型正在作为一种新型的算法和工具，成为整个人工智能技术新的制高点和新型的基础设施。 </font> 可以说大模型是一种变革性的技术，它可以显著地提升人工智能模型在应用中的性能表现，将人工智能的算法开发过程由传统的烟囱式开发模式转向集中式建模，解决人工智能应用落地过程中的场景碎片化，模型结果和模型训练需求零散的痛点。



### 最强的中文大模型--清华大学ChatGLM介绍

ChatGLM是由清华大学自主研发的，基于<font color="red">GLM（General Language Model）</font> 架构的，最新型最强大的深度学习大模型之一。 

ChatGLM 是用来最先进的深度学习前沿技术，经过约1TB标识符的中英双语训练，辅以 <font color="red">监督微调</font> ， <font color="blue">特定任务指令（Prompt）训练</font>，<font color="red">人类反馈强化学习</font>等技术，针对中文问答和对话进行了优化。

CHatGLM能够处理多种类型的自然语言任务。它可以<font color="red">回答问题</font> ，<font color="blue">生成文本</font> ，<font color="red">翻译语言</font>，<font color="blue">推理和推断</font>等。因此，它可以应用于许多不同的领域。



ChatGLM的优势

* 出色的对话生成能力
* 翻译能力。 可以将一种语言翻译成另一种语言，从而帮助用户客户语言交流的障碍。 
* 可以进行推理和推断。 他可以理解和应用逻辑和常识，从而帮助用户解决一些需要推理和推断恶毒问题。 



### 大模型的应用前景

* 赋能制造业
  * 人工智能大模型能够大幅提高制造业从研发，销售到售后各个环节的工作效率。 （RPA： Robotic Process Automation 机器人流程自动化）
* 赋能医疗行业
* 赋能金融行业
  * 对于银行业
  * 对于保险业
  * 对于证券期货业
* 赋能乃至颠覆传媒与互联网行业
  * 人工智能大模型将显著提升文娱内容生产效率，较低成本。 
  * 人工智能大模型将颠覆互联网已有业态及场景入口。
  * 内容聚合分发平台
  * 生活服务平台
  * 电商购物平台
  * 社交社区







## 第二章 PtTorch2.0 深度学习环境搭建

无论是构建深度学习应用程序还是应用已完成训练的项目到某项具体项目中，都需要使用编程语言完成设计者的目的。

Python是深度学习的首选开发语言，很多第三方提供了集成<font color="red">大量科学计算类库的Python标准安装包</font> ，常用的是Miniconda和Anacoda。 Python是一个脚本语言，如果不适应Miniconda或者Anaconda，那么第三方库的安装会比较困难，导致各个库之间的依赖关系变得复杂，从而导致安装和使用问题。因此，这里推荐安装Miniconda来替代原生Python语言的安装。 



### Miniconda 安装

疑惑？： 安装好minioconda之后，还使用pip来安装软件，感觉不对劲，不应该使用conda来安装吗？



### Python代码小练习：计算Softmax函数

对于Python科学计算来说，最简单的想法就是可以将数学公式直接表达成程序语言，可以说，Python满足了这个想法。 



Softmax用以解决概率计算中概率结果大而占绝对优势的问题。利润函数计算结果中的2个值a和b，且a >b,  如果简单地以值的大小为单位衡量的话，那么在后续的使用过程中，a永远被选用，而b由于数值较小，不会被选择，但是有时候也需要使用数值较小的b，Softmax就可以解决这个问题。 

Softmax按照改了选择a和b，由于a的概率值大于b，因此在计算时，a经常hui



### 安装PyTorch 2.0

对于需要调用专用编译器的PyTorch来说，不同的显卡需要安装不同的依赖计算包。



## 第三章 从零开始学习 PyTorch 2.0



























